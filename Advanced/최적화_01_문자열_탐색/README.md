# 문자열 탐색

## ▶ Hasing (해싱)
● 하나의 디렉토리에 존재 가능한 **파일의 수에 제한이 없음**  
  → 디렉토리 경로를 따라가기, 디렉토리 내에 존재하는 파일들 나열하기, 특정 파일의 존재 유무를 판별하기 등의 검색 기반 작업들은 성능 저하의 원인이 됨.  

● 해싱은 **특정 항목 검색**시, 탐색 키에 대한 **산술적 연산으로 key가 있는 위치를 계싼**하여 바로 검색하는 방법. **→ O(1)**  

● 직접 번지 테이블(배열) 사용  
  → **전체 key들의 집합이 작은 경우에 효율적**  
  → key가 테이블의 특정 위치에 저장됨  
  → **테이블 배열의 크기 = 전체 key들의 집합의 크기**  
  
### Hash table (해시 테이블)★★  
● 전체 key들의 집합이 클 때, 현실적인 컴퓨터 메모리 공간에서 테이블 생성 불가능  

● 실제 저장되는 key들의 집합이 전체 key들의 집합에 비해 상대적으로 작아서 많은 메모리가 누수됨.  
  
● 모든 가능한 key들의 집합(U)에 비해 실제 사용되는 key들의 집합(K)가 작을 경우 〓＞ **Hash table 메모리 공간 < 직접 번지 테이블 메모리 공간**  
  → 저장 공간을 K로 줄임, key값 자료의 저장할 위치를 계산하는 **해시 함수** 사용  
  → key값 자료를 해시 함수의 위치에 저장  
  
 ### Hash function (해시 함수)
 ● 모든 key들의 집합(U)를 해시 테이블(T)의 위치에 대응시킴  
  → 테이블의 index 범위 줄여줌  
  → hash_function(key)는 key의 **해시 값(주소)**라고 함  

※ 복수의 key가 **동일한 위치**가 되는 상황을 **Hash collision(충돌)**이라함  

### Collision (충돌)
● 서로 다른 key값을 해시 함수에 적용했을 때, **반환된 해시 주소가 동일한 경우**  

● 해시 함수가 아무리 해시 주소를 공평하게 분배해도 **해시 테이블에 저장되는 key에 해당하는 자료의 수가 증가**하면 충돌 불가피  

● 이러한 충돌의 해결 방안으로는 **Chaining(체이닝), Open addressing(개방 주소법)**등이 존재함.  

#### Chaning (체이닝)★
● 해시 테이블의 구조를 변경하여, **각 bucket(버킷)에 하나 이상의 key값을 가지는 자료가 저장** 될 수 있도록 하는 방법  
  → 하나의 bucket에 여러 개의 key값을 저장하도록 하기 위해 **Linked List 활용**  

![image](https://user-images.githubusercontent.com/33312417/236147145-3b944308-7d32-46a1-9464-a7cd6ce1871d.png)



#### Open addressing (개방 주소법)★
● 해시 함수로 구한 주소에 빈 공간이 없어 충돌이 발생하면, **그 다음 공간에 빈 공간 여부를 조사**  
  → 빈 공간이 있으면, 탐색 key에 대한 항목 저장  
  → 빈 공간이 없으면, 공간이 나올 때까지 탐색 반복  

![image](https://user-images.githubusercontent.com/33312417/236147048-1d1a1a68-95c2-4fbb-8d8a-380b3a7e7e7e.png)



 
## ▶ 문자열 매칭★★
● 많은 응용 분야에서 중요한 요소  
  1. Infomation Retrieval(정보 검색): 키워드 기반의 웹페이지 검색  
  2. Communication Systemp(통신 시스템): 텍스트 메시지, E-mail 전송, E-book 다운로드 등  
  3. Programming System(프로그래밍 시스템): 컴파일러, 인터프리터 등  
  4. Genomics(유전체학): DNA를 문자열 형태(A, C, T, G)로 표현 후 처리  
  
## Pattern matching(패턴 매칭)★★★
● 텍스트 문자열에 **패턴 문자열의 포함 여부**를 탐색하는 것  
  → 브루트포스, 카프-라빈, KMP 알고리즘, 보이어-무어 알고리즘 등  

### Brute-Force (브루트 포스) 〓 O(N * M)
● **텍스트 문자열을 처음부터 끝까지 차례대로 순회**하면서 패턴 내의 문자들을 일일이 비교하는 방식으로 동작 

● 비교할 패턴과 원본 문자열 모두 **첫 문자열부터 시작**  

● 최악의 경우, **텍스트의 모든 위치에서 패턴을 비교**  

### Karp-Rabin (카프-라빈 알고리즘) 〓 O(N + M) ~ O(N * M)
● **해시 함수** 사용  

● **패턴의 해시 값**과 텍스트 내의 패턴의 길이 만큼의 **문자열에 대한 해시 값을 비교**  

● 패턴 길이 만큼의 문자열을 한 글자씩 읽어서 해시 값을 계산하지 않고, 새로 추가되는 문자와 그전에 읽었던 값을 이용하여 해시 값 계산(**이전 해시 값을 이용해서 다음 해시 값을 구함**).  

● 최악의 경우, O(N *M)이지만 평균적으로는 **선형에 가까운 빠른 속도를 가지는 알고리즘**  

※ 주의 사항 ※  
1. 처음 해시 값을 구할 때는 **찾고자 하는 문자열에서 패턴 길이 만큼 읽음**  

2. 패턴의 길이가 커지면 길이를 일정 자릿수로 맞추기 위해 **모듈러(Mod) 연산 진행**  

3. 해시 값이 일치하면 **실제 문자열이 일치하는지도 검사**  

### Knuth-Morris-Pratt (KMP 알고리즘) 〓 O(N + M)
● 알고리즘을 제안한 사람들의 이름 첫글자를 따옴  

● 불일치가 발생한 텍스트 문자열의 앞부분에 어떤 문자가 있는지 미리 알고 있으므로, **불일치가 발생한 앞부분에 대하여 다시 비교하지 않고 매칭 수행##  

● 불일치가 발생하면, **다음 비교할 위치를 미리 계산**해서, 불필요한 시작 최소화  
  → 패턴의 모든 위치마다 불일치가 발생하면, 이동할 위치를 계산해서 저장  
  → 패턴의 길이 만큼 별도의 **next[pattern_length] List** 필요  
  
● **next[]**  
  → 불일치 발생 시 돌아갈 곳을 저장하는 List.  
  → 최대 패턴 길이만큼의 **접두어, 접미어**가 필요함.  
  → 문자열의 모든 부분 문자열들은 모든 접미어들의 모든 접두어들의 집합   
  
### (보이어-무어 알고리즘) 〓 O(N) ~ O(N * M)
● 패턴의 **역순**으로 비교  
  → 대부분의 불일치는 앞부분보단 뒷부분에서 일어날 확률이 높다는 성질에 기반.  
  
● 패턴의 마지막에서 불일치 했을 때  
  1. 해당 문자가 패턴 내에 존재하지 않는 경우 〓 **패턴의 길이만큼 점프**  
  
  2. 해당 문자가 패턴 내에 존재하는 경우 〓 패턴에서 일치하는 문자를 찾아서 **서로 일치되는 자리 만큼 점프**  

● 점프해야할 값에 대한 정보를 담는 **skip[] List**가 필요함  

### Python 내부 알고리즘
● **in**  
  → 연산자, 시퀀스 자료형에서 사용 가능.  
`pattern in string`  
 
● **find(검색할 문자열, [검색 시작 인덱스, 검색 종료 인덱스])**  
  → 문자열 클래스 제공
  → 검색 성공시 문자열에서 패턴을 찾은 시작 인덱스 반환, 검색 실패 시 -1 반환
  → 내부적으로 보이어-무어 알고리즘을 활용한 기법으로 구현 됨
`string.find(pattern)`  
 
 
## ▶ Trie (트라이)
● 정보 검색(Re**trie**val)에 사용된 자료구조로, 1960년 E.Fredkin에 의해 소개.  
 
● **문자열의 집합을 표현**하는 **트리**   
 
### 접미어 트라이
● 문자열의 **모든 접미어**를 **Trie로 표현**  

● 길이 N인 문자열에는 N개의 접미어가 존재  

● **부분 문자열 검사**에 용이함  
  → "BA"가 "ABAC"의 부분 문자열인가? 
  `한 문자씩 Root에서 대응되는 간선을 따라감`  

● **두 접미어의 최장 공통 접두어 찾기**  
  → "ABAC"와 "AC"의 최장 공통 접두어는 무엇인가?  
  `두 접미어의 끝 글자에 대응하는 노드 선택`  
  `Longest Common Ancestor(가장 가까운 공통 조상) 탐색`  
  `공통 접두어 만듦(Root에서 공통 조상까지 경로 = 두 접미어의 최장 공통 접두어가 됨)`  
  
● **사전적 순서로 정렬된 K번째 접미어 찾기**  
  → "ABAC"에서 사전적 순서로 3번째 접미어는 무엇인가?  
  `DFS로 문자열들을 생성하면 사전적 순서로 정렬됨`  
  `생성된 문자열들을 메모리에 모두 저장하지 않고 인덱스 값만 저장`  
  
### Compressed Trie (압축된 트라이)
● 노드들과 간선들을 **부분 문자열로 압축**  
● 단말노드의 개수는 동일하지만 내부 노드 개수 감소  
● 자식이 하나만 있는 노드들을 하나의 간선으로 묶어서 표현한 형태  

![image](https://user-images.githubusercontent.com/33312417/236171086-dcabbdcb-76bf-41c0-9dd6-181de5e6d681.png)

@@@@@@@@@@@@@@@@@@@@@

## ▶ Suffix tree (접미어 트리)
● 하나의 문자열의 **모든 접미어들을 포함**하는 Trie의 압축된 표현  
  → 압축되었어도, 여전히 **많은 메모리 필요**  
  
● 1973년 Weiner에 의해 소개되었고, 이후 공간 복잡도를 줄이기 위해 "접미어 배열"이 알려짐  

● 문자열 연산에 필요한 **알고리즘을 빠르게 구현 가능**  

● 특징 (문자열 S, 길이 s)  
  → 1 ~ s까지 번호가 부여된 s개의 단말 노드를 가짐  
  → Root를 제외한 내부 노드들은 최소 2개의 자식 노드를 가짐  
  → 각 간선은 문자열 S의 부분 문자열 Label(라벨)이 부여됨  
  → 한 노드에서 나가는 두 개의 간선이 "동일한 문자로 시작하는 문자열 라벨"을 가질 수 없음  
  → Root에서 단말 노드 i까지의 경로에서, 존재하는 문자열 라벨들을 연결한 문자열은 접미어 S[i...s], (1 <= i <= s)  

● 하나의 접미어가 다른 접미어의 접두어가 되는 경우엔?  
  → 문자열 S의 끝에 **특수한 문자 "$" 추가**  
  → "$"는 Termination character(종료 문자)라 하고, 문자 비교 시 **가장 작은 값을 가지는 문자**  
  
  → 간선에 부여된 라벨을 효과적으로 저장하기 위해 **부분 문자열 T[i...j]의 인덱스 시작과 끝(i, j) 저장**  

● Suffix tree의 응용  
  → Exact string matching (문자열 매칭)  
  → Substring matching (부분 문자열 매칭)  
  → **Longest commont substring of 2 strings (최장 공통 부분 문자열)**  
  
● 접미어 트리의 생성 - Trivial 알고리즘  
  ##### 해당 Trie 단원 자체가 이해가 안 간다..
  
## ▶ Suffix array (접미어 배열)
● 텍스트의 접미어들을 사전식으로 나열한 배열로, 1990년에 Manber와 Myers에 의해 소개됨.  

● Python에서는 배열대신 List로 구현됨.  

● Suffix tree보다 **메모리를 좀 더 효율적**으로 사용하지만 **다소느림**  

● 텍스트의 인덱싱, 데이터 압축, 생물정보학(Bio-informatics)등의 다양한 분야에 사용됨.  

● 접미어 배열의 **복잡도**  
  → O(n)의 메모리 크기  
  → O(n log n) 시간에 생성  
  → 텍스트 T에 패턴 P의 존재를 O(|P| + log n) 시간에 계산  
  
● 접미어 배열의 **장점**  
  → 생성 방법이 Suffix tree에 비해 **간단함**  
  → **적은 메모리**로 구현 가능  
  → 2개의 선형 크기의 List로 구성, 전형적으로 Suffix tree에 비해 1/4 크기의 메모리를 사용한다고 알려져 있음  
  
 
![image](https://user-images.githubusercontent.com/33312417/236179096-14aca982-0050-4912-8a7a-89fbd5063aa8.png)
→ 모든 접미어들의 시작 인덱스를 순차적으로 저장해두고,  
→ 정렬을 통해 사전순으로 정렬된 접미어들의 시작 인덱스를 저장함  

### LCP 배열 (Longest Common Prefix, 최장 공통 접두어)
● 접미어 배열의 보조적인 자료 구조로, 최장 공통 접두어 배열 생성  

● 정렬된 접미어 배열에서 연속적인 2개의 접미어들 사이의 최장 공통 접두어의 길이를 저장  

● 접미어 배열의 순회, 패턴 매칭을 효율적으로 수행하는데 사용  

![image](https://user-images.githubusercontent.com/33312417/236179360-43870f71-e0c8-467e-94ab-2a0b4652c43f.png)
→ 접미어 배열 생성, LCP 배열 생성  
→ 사전순으로 가장 처음에 오는 접미어의 LCP 값 = 0  
→ 다음 접미어부터 바로 이전 접미어와의 공통되는 가장 긴 접두어의 길이를 계산하여 저장함   

![image](https://user-images.githubusercontent.com/33312417/236180297-7836fb94-2c92-45fb-8c2a-a23a5a47b976.png)

@@@@@@@@@@@@@@@@@@@@@

## ▶ 압축
● 텍스트, 이미지(jpg), 음원(MP3), 영상(DVD) 데이터 등을 포함해 거의 **모든 응용 분야**에서 사용  

● 대부분의 데이터 파일에는 **Redundancy(중복) 존재**  

● 데이터 압축 = **저장 공간 절약** & **데이터 전송 시간 절약**  

● 주요 압축 기법들  
 → Run-Length Encoding / Huffman Coding / Lampel-Ziv-Welch Encoding / Arithmetic Coding  

● 데이터 압축 관련 용어  
  1. Encoding(인코딩): 데이터 **압축**  
  2. Decoding(디코딩): 데이터 **복구**  
  `바이너리 데이터 → Encoder → 압축 데이터 → Decoder → 복구된 원본(또는 근사)`  
  
  → 압축률: 압축 데이터의 비트 수 ÷ 바이너리 데이터의 비트 수  
  → 데이터 압축: 손실/무손실 압축으로 구분됨  
  
### RLE (Run Length Encoding)
![image](https://user-images.githubusercontent.com/33312417/236182055-454ed3e7-e11c-4938-98a8-cf1b378b3c11.png)

● 1:47 ~  

+ 허프만 코드  
@@@@@@@@@@@@@@@@@@@@@
